What is an operating system :
    An operating system (OS) is a software that manages computer hardware and software resources and provides common services for computer programs.
    It acts as an intermediary between the computer hardware and the user, facilitating the execution of applications and providing an interface for interaction.

Types of operating systems :
    Types of operating systems include:
    Single-user, single-tasking: These are simple operating systems that allow only one user to execute one program at a time.
    Single-user, multi-tasking: These operating systems allow a single user to run multiple programs simultaneously by rapidly switching between them.
    Multi-user: These operating systems support multiple users accessing the system simultaneously.
    Real-time: Real-time operating systems are designed for time-sensitive applications, where response times must be guaranteed within specific time constraints.
    Network: These operating systems are specifically designed for distributed computing environments and enable communication and resource sharing across multiple computers.

What is Parallelism :
    Parallelism refers to the concept of executing multiple tasks or processes simultaneously. It allows for the efficient utilization of multiple resources, such as multiple CPU cores or processors, to complete tasks faster.
    Parallelism can be achieved through various techniques like multi-threading, multiprocessing, and distributed computing.

What is a process :
    A process is an instance of a program that is being executed by an operating system. It consists of the program code, data, and resources necessary for its execution.
    A process has its own memory space, program counter, and other attributes that help the operating system manage its execution.

Process states :
    Process states refer to the various stages a process can be in during its lifecycle. Common process states include:
    1- New: The process is being created.
    2- Ready: The process is waiting to be assigned to a processor.
    3- Running: The process is currently being executed by a processor.
    4- Blocked (or Waiting): The process is waiting for an event or resource.
    5- Terminated: The process has finished execution.

Process Control Block (PCB) :
    A Process Control Block (PCB) is a data structure used by the operating system to store information about a process.
    It contains details such as the process ID, program counter, register information, memory allocation, and other relevant information required by the operating system to manage and control the process.

What is Thread :
    A thread is a basic unit of CPU utilization, representing a single sequence of instructions within a process.
    Threads share the same memory space as their parent process, allowing them to communicate and share data more efficiently.
    Multiple threads can exist within a single process and can execute independently, providing concurrent execution of tasks within the same program.

Process vs. thread:
    A process is a self-contained execution environment with its own memory and resources, whereas a thread is a unit of execution within a process. Processes are isolated from each other, 
    while threads share resources and can communicate more easily. Creating a new process is more resource-intensive than creating a new thread.

What is multi threading :
    Multithreading is the concurrent execution of multiple threads within the same process. It enables a program to perform multiple tasks at the same time, utilizing the available resources efficiently.
    Multithreading can lead to improved responsiveness, better resource utilization, and enhanced performance in certain scenarios.

What is advantage and disadvantage of threads :
    -Advantages of threads include increased responsiveness, improved resource sharing, and better utilization of multi-core processors.
        Threads can execute concurrently and handle multiple tasks simultaneously, allowing for efficient use of system resources.
    -Disadvantages of threads include increased complexity in programming and debugging, as threads share memory and can cause synchronization issues.
        Inefficient thread management can lead to thread interference, deadlocks, and race conditions, which can be challenging to identify and resolve.

Critical section problem :
    The critical section problem arises in concurrent programming when multiple threads or processes access shared resources or variables concurrently. 
    The problem is to ensure that only one thread/process can access the critical section at a time to avoid race conditions and maintain data integrity.

Producer consumer problem :
    The producer-consumer problem is a classic synchronization problem where one or more threads (producers) generate data, and one or more threads (consumers) consume/process that data.
    The challenge is to synchronize the producers and consumers to prevent issues like data corruption or deadlock.

Race conditions (Data Race) :
    Race conditions occur when multiple threads or processes try to access and modify shared resources simultaneously, leading to unpredictable and erroneous results.
    Race conditions can result in data inconsistencies or program crashes.

Deadlock :
    Deadlock is a situation where two or more threads or processes are unable to proceed because each is waiting for the other to release a resource.
    Deadlocks can lead to system stagnation and require intervention to resolve.

Locks or mutexes :
    Locks (or mutexes) are synchronization mechanisms used to control access to shared resources.
    They allow only one thread or process at a time to acquire the lock and access the critical section, ensuring mutual exclusion and preventing race conditions.

Process Synchronization :
    Process synchronization refers to the coordination and synchronization of processes or threads to maintain data consistency and avoid issues like race conditions and deadlocks.
    Synchronization mechanisms like locks, semaphores, and condition variables are used to manage access to shared resources and coordinate the execution of concurrent processes or threads.

The dining philosophers problem :
    The dining philosophers problem is a classic synchronization problem that illustrates the challenges of resource allocation and deadlock avoidance.
    In the problem, a group of philosophers is seated around a table, and each philosopher alternates between thinking and eating.
    The philosophers share a limited number of forks placed between them, and to eat, a philosopher needs both the fork on their left and the fork on their right.
    The problem is to design a synchronization solution that prevents deadlocks, where all philosophers are simultaneously waiting for a second fork.
